{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ee2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a79259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the insurance data set\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5914f014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekc if the data has null value\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84640297",
   "metadata": {},
   "source": [
    "*  unique() is function allow us to see the type of our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd3a214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'no'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sex.unique()\n",
    "#df.children.unique()\n",
    "#df.smoker.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5cdee",
   "metadata": {},
   "source": [
    "* we should apply one hard encoding--- turn non-numerical value to  numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cb45ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0      19  27.900         0  16884.92400           1         0          0   \n",
       "1      18  33.770         1   1725.55230           0         1          1   \n",
       "2      28  33.000         3   4449.46200           0         1          1   \n",
       "3      33  22.705         0  21984.47061           0         1          1   \n",
       "4      32  28.880         0   3866.85520           0         1          1   \n",
       "...   ...     ...       ...          ...         ...       ...        ...   \n",
       "1333   50  30.970         3  10600.54830           0         1          1   \n",
       "1334   18  31.920         0   2205.98080           1         0          1   \n",
       "1335   18  36.850         0   1629.83350           1         0          1   \n",
       "1336   21  25.800         0   2007.94500           1         0          1   \n",
       "1337   61  29.070         0  29141.36030           1         0          0   \n",
       "\n",
       "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0              1                 0                 0                 0   \n",
       "1              0                 0                 0                 1   \n",
       "2              0                 0                 0                 1   \n",
       "3              0                 0                 1                 0   \n",
       "4              0                 0                 1                 0   \n",
       "...          ...               ...               ...               ...   \n",
       "1333           0                 0                 1                 0   \n",
       "1334           0                 1                 0                 0   \n",
       "1335           0                 0                 0                 1   \n",
       "1336           0                 0                 0                 0   \n",
       "1337           1                 0                 1                 0   \n",
       "\n",
       "      region_southwest  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1333                 0  \n",
       "1334                 0  \n",
       "1335                 0  \n",
       "1336                 1  \n",
       "1337                 0  \n",
       "\n",
       "[1338 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot=pd.get_dummies(df)\n",
    "df_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df7f3d",
   "metadata": {},
   "source": [
    "* create x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c67149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16884.92400\n",
       "1        1725.55230\n",
       "2        4449.46200\n",
       "3       21984.47061\n",
       "4        3866.85520\n",
       "           ...     \n",
       "1333    10600.54830\n",
       "1334     2205.98080\n",
       "1335     1629.83350\n",
       "1336     2007.94500\n",
       "1337    29141.36030\n",
       "Name: charges, Length: 1338, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_one_hot.drop(\"charges\",axis=1)\n",
    "Y=df_one_hot[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6164d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see X and Y\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3caa07d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "456df741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1338, 1070, 268)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "len(X),len(Y),len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0a308fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 615us/step - loss: 8637.0996 - mae: 8637.0996\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 585us/step - loss: 7886.7769 - mae: 7886.7769\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 617us/step - loss: 7558.1470 - mae: 7558.1470\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 575us/step - loss: 7792.0225 - mae: 7792.0225\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 566us/step - loss: 7748.3887 - mae: 7748.3887\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 743us/step - loss: 7595.3940 - mae: 7595.3940\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 811us/step - loss: 7589.9849 - mae: 7589.9849\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 685us/step - loss: 7698.5586 - mae: 7698.5586\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7496.7778 - mae: 7496.7778\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 627us/step - loss: 7493.1738 - mae: 7493.1738\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 755us/step - loss: 7769.7314 - mae: 7769.7314\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 618us/step - loss: 7706.9043 - mae: 7706.9043\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 629us/step - loss: 7687.7227 - mae: 7687.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 652us/step - loss: 7689.8999 - mae: 7689.8999\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 657us/step - loss: 7393.5322 - mae: 7393.5322\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 773us/step - loss: 7780.6982 - mae: 7780.6982\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 637us/step - loss: 7578.5117 - mae: 7578.5117\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 765us/step - loss: 7750.8354 - mae: 7750.8354\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 563us/step - loss: 7739.2148 - mae: 7739.2148\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 691us/step - loss: 7875.0664 - mae: 7875.0664\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 622us/step - loss: 7466.6768 - mae: 7466.6768\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 558us/step - loss: 7941.2329 - mae: 7941.2329\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 595us/step - loss: 7640.2725 - mae: 7640.2725\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 586us/step - loss: 7539.2671 - mae: 7539.2671\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 613us/step - loss: 7619.9653 - mae: 7619.9653\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 581us/step - loss: 7644.1714 - mae: 7644.1714\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 665us/step - loss: 7709.0371 - mae: 7709.0371\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 607us/step - loss: 7366.8667 - mae: 7366.8667\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 840us/step - loss: 7444.3154 - mae: 7444.3154\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 673us/step - loss: 7616.4087 - mae: 7616.4087\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 657us/step - loss: 7686.3853 - mae: 7686.3853\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 833us/step - loss: 7548.0996 - mae: 7548.0996\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 584us/step - loss: 7501.5537 - mae: 7501.5537\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 535us/step - loss: 7363.4165 - mae: 7363.4165\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 603us/step - loss: 7295.4473 - mae: 7295.4473\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 581us/step - loss: 7569.8823 - mae: 7569.8823\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 511us/step - loss: 7548.2007 - mae: 7548.2007\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 613us/step - loss: 7424.3979 - mae: 7424.3979\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 644us/step - loss: 7529.7734 - mae: 7529.7734\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 638us/step - loss: 7467.3237 - mae: 7467.3237\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 650us/step - loss: 7635.9292 - mae: 7635.9292\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 621us/step - loss: 7536.8398 - mae: 7536.8398\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 702us/step - loss: 7616.5854 - mae: 7616.5854\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 626us/step - loss: 7439.4941 - mae: 7439.4941\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 566us/step - loss: 7538.0142 - mae: 7538.0142\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 600us/step - loss: 7415.1465 - mae: 7415.1465\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 573us/step - loss: 7420.6938 - mae: 7420.6938\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 814us/step - loss: 7509.9844 - mae: 7509.9844\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 683us/step - loss: 7541.1128 - mae: 7541.1128\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7467.8633 - mae: 7467.8633\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 804us/step - loss: 7389.3560 - mae: 7389.3560\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 594us/step - loss: 7499.7754 - mae: 7499.7754\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 665us/step - loss: 7523.9282 - mae: 7523.9282\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 674us/step - loss: 7243.3120 - mae: 7243.3120\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 635us/step - loss: 7429.5869 - mae: 7429.5869\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 661us/step - loss: 7313.4009 - mae: 7313.4009\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 574us/step - loss: 7526.3877 - mae: 7526.3877\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 608us/step - loss: 7542.2671 - mae: 7542.2671\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 513us/step - loss: 7576.9282 - mae: 7576.9282\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 510us/step - loss: 7546.4048 - mae: 7546.4048\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 9661.6816 - mae: 9661.681 - 0s 523us/step - loss: 7351.2280 - mae: 7351.2280\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 532us/step - loss: 7302.1440 - mae: 7302.1440\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 555us/step - loss: 7393.0884 - mae: 7393.0884\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 529us/step - loss: 7442.2886 - mae: 7442.2886\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 529us/step - loss: 7492.6792 - mae: 7492.6792\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 512us/step - loss: 7561.9165 - mae: 7561.9165\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 594us/step - loss: 7340.5142 - mae: 7340.5142\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 534us/step - loss: 7496.0854 - mae: 7496.0854\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 538us/step - loss: 7617.0317 - mae: 7617.0317\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 530us/step - loss: 7641.1948 - mae: 7641.1948\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 599us/step - loss: 7084.2749 - mae: 7084.2749\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 546us/step - loss: 7240.4907 - mae: 7240.4907\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 505us/step - loss: 7283.4888 - mae: 7283.4888\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 517us/step - loss: 7335.5088 - mae: 7335.5088\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 556us/step - loss: 7275.6411 - mae: 7275.6411\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 510us/step - loss: 7313.1860 - mae: 7313.1860\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 517us/step - loss: 7485.7588 - mae: 7485.7588\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 542us/step - loss: 7352.2803 - mae: 7352.2803\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7520.5713 - mae: 7520.5713\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 529us/step - loss: 7279.3779 - mae: 7279.3779\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 520us/step - loss: 7273.8477 - mae: 7273.8477\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 526us/step - loss: 7176.5210 - mae: 7176.5210\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 505us/step - loss: 7425.6299 - mae: 7425.6299\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 536us/step - loss: 7403.1294 - mae: 7403.1294\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 533us/step - loss: 7356.0078 - mae: 7356.0078\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 534us/step - loss: 7484.7266 - mae: 7484.7266\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 509us/step - loss: 7217.6089 - mae: 7217.6089\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 512us/step - loss: 7261.0000 - mae: 7261.0000\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 512us/step - loss: 7134.1562 - mae: 7134.1562\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 526us/step - loss: 7083.4355 - mae: 7083.4355\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 530us/step - loss: 7254.1782 - mae: 7254.1782\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 501us/step - loss: 7268.7456 - mae: 7268.7456\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 508us/step - loss: 7470.5225 - mae: 7470.5225\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 540us/step - loss: 7210.9536 - mae: 7210.9536\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 562us/step - loss: 7395.6816 - mae: 7395.6816\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 587us/step - loss: 7328.0884 - mae: 7328.0884\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 562us/step - loss: 7230.4395 - mae: 7230.4395\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 556us/step - loss: 7261.3940 - mae: 7261.3940\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 553us/step - loss: 7342.5684 - mae: 7342.5684\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 484us/step - loss: 7106.1714 - mae: 7106.1714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2027f3336d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a model neural network:\n",
    "tf.random.set_seed(42)\n",
    "# create the model:\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# compile the model:\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "# fitten the model\n",
    "model.fit(X_train,Y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11dddae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4b2d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 916us/step - loss: 7023.3291 - mae: 7023.3291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.3291015625, 7023.3291015625]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result of insurance model on test data\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47fa57d",
   "metadata": {},
   "source": [
    "#### to try improving our model : run to experiment \n",
    "* add extar layer with more hidden unit use adam optimizer\n",
    "* train forlanger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc233a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 791us/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 654us/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 700us/step - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 687us/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 677us/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 742us/step - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 691us/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 713us/step - loss: 7528.8413 - mae: 7528.8413\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 754us/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 740us/step - loss: 7409.0815 - mae: 7409.0815\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 691us/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 802us/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 642us/step - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 678us/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 990us/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 702us/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 657us/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 669us/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 671us/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 605us/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 655us/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 764us/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 624us/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 791us/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 706us/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7024.3511 - mae: 7024.3511\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 864us/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 826us/step - loss: 6969.0122 - mae: 6969.0122\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 791us/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 703us/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 700us/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 741us/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 664us/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 665us/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 647us/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 602us/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 679us/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 611us/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 636us/step - loss: 6618.1016 - mae: 6618.1016\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 603us/step - loss: 6585.8643 - mae: 6585.8643\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 623us/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 648us/step - loss: 6530.0435 - mae: 6530.0435\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 700us/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 624us/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 655us/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 607us/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 637us/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 614us/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 619us/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 661us/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 605us/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 658us/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 591us/step - loss: 6351.5273 - mae: 6351.5273\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 602us/step - loss: 6337.6602 - mae: 6337.6602\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 643us/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 646us/step - loss: 6310.1943 - mae: 6310.1943\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 698us/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 639us/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 622us/step - loss: 6253.0112 - mae: 6253.0112\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 676us/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 632us/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 653us/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 609us/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 547us/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 634us/step - loss: 6148.8398 - mae: 6148.8398\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 637us/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 560us/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 629us/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 724us/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 706us/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 639us/step - loss: 6031.3848 - mae: 6031.3848\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 631us/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 583us/step - loss: 5995.2178 - mae: 5995.2178\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 626us/step - loss: 5963.0718 - mae: 5963.0718\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 672us/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 603us/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 648us/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 641us/step - loss: 5861.6992 - mae: 5861.6992\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 693us/step - loss: 5834.3071 - mae: 5834.3071\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 619us/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 747us/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 607us/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 646us/step - loss: 5711.3477 - mae: 5711.3477\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 612us/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 601us/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 593us/step - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 583us/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 694us/step - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 601us/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 669us/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 647us/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 712us/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 597us/step - loss: 5288.8164 - mae: 5288.8164\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 622us/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 592us/step - loss: 5170.9365 - mae: 5170.9365\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 611us/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 645us/step - loss: 5060.0854 - mae: 5060.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x202023c2070>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# create a model\n",
    "model_1= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "             #optimizer=tf.keras.optimizers.SGD(),\n",
    "             optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# fiiting the model\n",
    "model_1.fit(X_train,Y_train,epochs=100,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a27ca79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 951us/step - loss: 4924.5093 - mae: 4924.5093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4924.50927734375, 4924.50927734375]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9793c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 992us/step - loss: 7023.3291 - mae: 7023.3291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.3291015625, 7023.3291015625]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da5ec91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:Layer dense_62 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 - 0s - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/300\n",
      "34/34 - 0s - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/300\n",
      "34/34 - 0s - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/300\n",
      "34/34 - 0s - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/300\n",
      "34/34 - 0s - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/300\n",
      "34/34 - 0s - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/300\n",
      "34/34 - 0s - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/300\n",
      "34/34 - 0s - loss: 7528.8413 - mae: 7528.8413\n",
      "Epoch 9/300\n",
      "34/34 - 0s - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/300\n",
      "34/34 - 0s - loss: 7409.0815 - mae: 7409.0815\n",
      "Epoch 11/300\n",
      "34/34 - 0s - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/300\n",
      "34/34 - 0s - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/300\n",
      "34/34 - 0s - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/300\n",
      "34/34 - 0s - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/300\n",
      "34/34 - 0s - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/300\n",
      "34/34 - 0s - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/300\n",
      "34/34 - 0s - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/300\n",
      "34/34 - 0s - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/300\n",
      "34/34 - 0s - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/300\n",
      "34/34 - 0s - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/300\n",
      "34/34 - 0s - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/300\n",
      "34/34 - 0s - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/300\n",
      "34/34 - 0s - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/300\n",
      "34/34 - 0s - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/300\n",
      "34/34 - 0s - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/300\n",
      "34/34 - 0s - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/300\n",
      "34/34 - 0s - loss: 7024.3511 - mae: 7024.3511\n",
      "Epoch 28/300\n",
      "34/34 - 0s - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/300\n",
      "34/34 - 0s - loss: 6969.0122 - mae: 6969.0122\n",
      "Epoch 30/300\n",
      "34/34 - 0s - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/300\n",
      "34/34 - 0s - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/300\n",
      "34/34 - 0s - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/300\n",
      "34/34 - 0s - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/300\n",
      "34/34 - 0s - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/300\n",
      "34/34 - 0s - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/300\n",
      "34/34 - 0s - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/300\n",
      "34/34 - 0s - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/300\n",
      "34/34 - 0s - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/300\n",
      "34/34 - 0s - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/300\n",
      "34/34 - 0s - loss: 6618.1016 - mae: 6618.1016\n",
      "Epoch 41/300\n",
      "34/34 - 0s - loss: 6585.8643 - mae: 6585.8643\n",
      "Epoch 42/300\n",
      "34/34 - 0s - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/300\n",
      "34/34 - 0s - loss: 6530.0435 - mae: 6530.0435\n",
      "Epoch 44/300\n",
      "34/34 - 0s - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/300\n",
      "34/34 - 0s - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/300\n",
      "34/34 - 0s - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/300\n",
      "34/34 - 0s - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/300\n",
      "34/34 - 0s - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/300\n",
      "34/34 - 0s - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/300\n",
      "34/34 - 0s - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/300\n",
      "34/34 - 0s - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/300\n",
      "34/34 - 0s - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/300\n",
      "34/34 - 0s - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/300\n",
      "34/34 - 0s - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/300\n",
      "34/34 - 0s - loss: 6351.5273 - mae: 6351.5273\n",
      "Epoch 56/300\n",
      "34/34 - 0s - loss: 6337.6602 - mae: 6337.6602\n",
      "Epoch 57/300\n",
      "34/34 - 0s - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/300\n",
      "34/34 - 0s - loss: 6310.1943 - mae: 6310.1943\n",
      "Epoch 59/300\n",
      "34/34 - 0s - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/300\n",
      "34/34 - 0s - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/300\n",
      "34/34 - 0s - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/300\n",
      "34/34 - 0s - loss: 6253.0112 - mae: 6253.0112\n",
      "Epoch 63/300\n",
      "34/34 - 0s - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/300\n",
      "34/34 - 0s - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/300\n",
      "34/34 - 0s - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/300\n",
      "34/34 - 0s - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/300\n",
      "34/34 - 0s - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/300\n",
      "34/34 - 0s - loss: 6148.8398 - mae: 6148.8398\n",
      "Epoch 69/300\n",
      "34/34 - 0s - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/300\n",
      "34/34 - 0s - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/300\n",
      "34/34 - 0s - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/300\n",
      "34/34 - 0s - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/300\n",
      "34/34 - 0s - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/300\n",
      "34/34 - 0s - loss: 6031.3848 - mae: 6031.3848\n",
      "Epoch 75/300\n",
      "34/34 - 0s - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/300\n",
      "34/34 - 0s - loss: 5995.2178 - mae: 5995.2178\n",
      "Epoch 77/300\n",
      "34/34 - 0s - loss: 5963.0718 - mae: 5963.0718\n",
      "Epoch 78/300\n",
      "34/34 - 0s - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/300\n",
      "34/34 - 0s - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/300\n",
      "34/34 - 0s - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/300\n",
      "34/34 - 0s - loss: 5861.6992 - mae: 5861.6992\n",
      "Epoch 82/300\n",
      "34/34 - 0s - loss: 5834.3071 - mae: 5834.3071\n",
      "Epoch 83/300\n",
      "34/34 - 0s - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/300\n",
      "34/34 - 0s - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/300\n",
      "34/34 - 0s - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/300\n",
      "34/34 - 0s - loss: 5711.3477 - mae: 5711.3477\n",
      "Epoch 87/300\n",
      "34/34 - 0s - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/300\n",
      "34/34 - 0s - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/300\n",
      "34/34 - 0s - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/300\n",
      "34/34 - 0s - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/300\n",
      "34/34 - 0s - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/300\n",
      "34/34 - 0s - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/300\n",
      "34/34 - 0s - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/300\n",
      "34/34 - 0s - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/300\n",
      "34/34 - 0s - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/300\n",
      "34/34 - 0s - loss: 5288.8164 - mae: 5288.8164\n",
      "Epoch 97/300\n",
      "34/34 - 0s - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/300\n",
      "34/34 - 0s - loss: 5170.9365 - mae: 5170.9365\n",
      "Epoch 99/300\n",
      "34/34 - 0s - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/300\n",
      "34/34 - 0s - loss: 5060.0854 - mae: 5060.0854\n",
      "Epoch 101/300\n",
      "34/34 - 0s - loss: 4987.7412 - mae: 4987.7412\n",
      "Epoch 102/300\n",
      "34/34 - 0s - loss: 4915.4458 - mae: 4915.4458\n",
      "Epoch 103/300\n",
      "34/34 - 0s - loss: 4847.4849 - mae: 4847.4849\n",
      "Epoch 104/300\n",
      "34/34 - 0s - loss: 4768.1797 - mae: 4768.1797\n",
      "Epoch 105/300\n",
      "34/34 - 0s - loss: 4683.4634 - mae: 4683.4634\n",
      "Epoch 106/300\n",
      "34/34 - 0s - loss: 4601.2051 - mae: 4601.2051\n",
      "Epoch 107/300\n",
      "34/34 - 0s - loss: 4513.4619 - mae: 4513.4619\n",
      "Epoch 108/300\n",
      "34/34 - 0s - loss: 4423.5933 - mae: 4423.5933\n",
      "Epoch 109/300\n",
      "34/34 - 0s - loss: 4339.2158 - mae: 4339.2158\n",
      "Epoch 110/300\n",
      "34/34 - 0s - loss: 4255.7852 - mae: 4255.7852\n",
      "Epoch 111/300\n",
      "34/34 - 0s - loss: 4174.8755 - mae: 4174.8755\n",
      "Epoch 112/300\n",
      "34/34 - 0s - loss: 4101.4229 - mae: 4101.4229\n",
      "Epoch 113/300\n",
      "34/34 - 0s - loss: 4031.7192 - mae: 4031.7192\n",
      "Epoch 114/300\n",
      "34/34 - 0s - loss: 3986.9080 - mae: 3986.9080\n",
      "Epoch 115/300\n",
      "34/34 - 0s - loss: 3944.5911 - mae: 3944.5911\n",
      "Epoch 116/300\n",
      "34/34 - 0s - loss: 3918.6138 - mae: 3918.6138\n",
      "Epoch 117/300\n",
      "34/34 - 0s - loss: 3896.7378 - mae: 3896.7378\n",
      "Epoch 118/300\n",
      "34/34 - 0s - loss: 3872.1240 - mae: 3872.1240\n",
      "Epoch 119/300\n",
      "34/34 - 0s - loss: 3851.9646 - mae: 3851.9646\n",
      "Epoch 120/300\n",
      "34/34 - 0s - loss: 3835.4441 - mae: 3835.4441\n",
      "Epoch 121/300\n",
      "34/34 - 0s - loss: 3829.4531 - mae: 3829.4531\n",
      "Epoch 122/300\n",
      "34/34 - 0s - loss: 3822.5393 - mae: 3822.5393\n",
      "Epoch 123/300\n",
      "34/34 - 0s - loss: 3814.8994 - mae: 3814.8994\n",
      "Epoch 124/300\n",
      "34/34 - 0s - loss: 3806.8054 - mae: 3806.8054\n",
      "Epoch 125/300\n",
      "34/34 - 0s - loss: 3795.5420 - mae: 3795.5420\n",
      "Epoch 126/300\n",
      "34/34 - 0s - loss: 3807.1851 - mae: 3807.1851\n",
      "Epoch 127/300\n",
      "34/34 - 0s - loss: 3797.8477 - mae: 3797.8477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/300\n",
      "34/34 - 0s - loss: 3791.7202 - mae: 3791.7202\n",
      "Epoch 129/300\n",
      "34/34 - 0s - loss: 3802.8027 - mae: 3802.8027\n",
      "Epoch 130/300\n",
      "34/34 - 0s - loss: 3789.7979 - mae: 3789.7979\n",
      "Epoch 131/300\n",
      "34/34 - 0s - loss: 3781.4004 - mae: 3781.4004\n",
      "Epoch 132/300\n",
      "34/34 - 0s - loss: 3774.9453 - mae: 3774.9453\n",
      "Epoch 133/300\n",
      "34/34 - 0s - loss: 3770.7568 - mae: 3770.7568\n",
      "Epoch 134/300\n",
      "34/34 - 0s - loss: 3769.5461 - mae: 3769.5461\n",
      "Epoch 135/300\n",
      "34/34 - 0s - loss: 3767.2349 - mae: 3767.2349\n",
      "Epoch 136/300\n",
      "34/34 - 0s - loss: 3766.0598 - mae: 3766.0598\n",
      "Epoch 137/300\n",
      "34/34 - 0s - loss: 3775.8564 - mae: 3775.8564\n",
      "Epoch 138/300\n",
      "34/34 - 0s - loss: 3783.4241 - mae: 3783.4241\n",
      "Epoch 139/300\n",
      "34/34 - 0s - loss: 3761.3586 - mae: 3761.3586\n",
      "Epoch 140/300\n",
      "34/34 - 0s - loss: 3762.6267 - mae: 3762.6267\n",
      "Epoch 141/300\n",
      "34/34 - 0s - loss: 3763.7026 - mae: 3763.7026\n",
      "Epoch 142/300\n",
      "34/34 - 0s - loss: 3765.6416 - mae: 3765.6416\n",
      "Epoch 143/300\n",
      "34/34 - 0s - loss: 3755.0134 - mae: 3755.0134\n",
      "Epoch 144/300\n",
      "34/34 - 0s - loss: 3750.5747 - mae: 3750.5747\n",
      "Epoch 145/300\n",
      "34/34 - 0s - loss: 3751.1660 - mae: 3751.1660\n",
      "Epoch 146/300\n",
      "34/34 - 0s - loss: 3756.9319 - mae: 3756.9319\n",
      "Epoch 147/300\n",
      "34/34 - 0s - loss: 3751.6326 - mae: 3751.6326\n",
      "Epoch 148/300\n",
      "34/34 - 0s - loss: 3756.2712 - mae: 3756.2712\n",
      "Epoch 149/300\n",
      "34/34 - 0s - loss: 3743.5854 - mae: 3743.5854\n",
      "Epoch 150/300\n",
      "34/34 - 0s - loss: 3738.7112 - mae: 3738.7112\n",
      "Epoch 151/300\n",
      "34/34 - 0s - loss: 3741.1479 - mae: 3741.1479\n",
      "Epoch 152/300\n",
      "34/34 - 0s - loss: 3742.1653 - mae: 3742.1653\n",
      "Epoch 153/300\n",
      "34/34 - 0s - loss: 3743.0076 - mae: 3743.0076\n",
      "Epoch 154/300\n",
      "34/34 - 0s - loss: 3737.0332 - mae: 3737.0332\n",
      "Epoch 155/300\n",
      "34/34 - 0s - loss: 3737.9741 - mae: 3737.9741\n",
      "Epoch 156/300\n",
      "34/34 - 0s - loss: 3736.7354 - mae: 3736.7354\n",
      "Epoch 157/300\n",
      "34/34 - 0s - loss: 3732.5813 - mae: 3732.5813\n",
      "Epoch 158/300\n",
      "34/34 - 0s - loss: 3729.4280 - mae: 3729.4280\n",
      "Epoch 159/300\n",
      "34/34 - 0s - loss: 3728.5618 - mae: 3728.5618\n",
      "Epoch 160/300\n",
      "34/34 - 0s - loss: 3733.9949 - mae: 3733.9949\n",
      "Epoch 161/300\n",
      "34/34 - 0s - loss: 3728.1074 - mae: 3728.1074\n",
      "Epoch 162/300\n",
      "34/34 - 0s - loss: 3725.3669 - mae: 3725.3669\n",
      "Epoch 163/300\n",
      "34/34 - 0s - loss: 3722.9504 - mae: 3722.9504\n",
      "Epoch 164/300\n",
      "34/34 - 0s - loss: 3727.0610 - mae: 3727.0610\n",
      "Epoch 165/300\n",
      "34/34 - 0s - loss: 3717.6611 - mae: 3717.6611\n",
      "Epoch 166/300\n",
      "34/34 - 0s - loss: 3720.3701 - mae: 3720.3701\n",
      "Epoch 167/300\n",
      "34/34 - 0s - loss: 3720.2913 - mae: 3720.2913\n",
      "Epoch 168/300\n",
      "34/34 - 0s - loss: 3717.2764 - mae: 3717.2764\n",
      "Epoch 169/300\n",
      "34/34 - 0s - loss: 3713.5598 - mae: 3713.5598\n",
      "Epoch 170/300\n",
      "34/34 - 0s - loss: 3708.0083 - mae: 3708.0083\n",
      "Epoch 171/300\n",
      "34/34 - 0s - loss: 3707.6401 - mae: 3707.6401\n",
      "Epoch 172/300\n",
      "34/34 - 0s - loss: 3709.0303 - mae: 3709.0303\n",
      "Epoch 173/300\n",
      "34/34 - 0s - loss: 3705.1501 - mae: 3705.1501\n",
      "Epoch 174/300\n",
      "34/34 - 0s - loss: 3709.5408 - mae: 3709.5408\n",
      "Epoch 175/300\n",
      "34/34 - 0s - loss: 3710.9673 - mae: 3710.9673\n",
      "Epoch 176/300\n",
      "34/34 - 0s - loss: 3706.6677 - mae: 3706.6677\n",
      "Epoch 177/300\n",
      "34/34 - 0s - loss: 3698.9148 - mae: 3698.9148\n",
      "Epoch 178/300\n",
      "34/34 - 0s - loss: 3695.3818 - mae: 3695.3818\n",
      "Epoch 179/300\n",
      "34/34 - 0s - loss: 3706.8618 - mae: 3706.8618\n",
      "Epoch 180/300\n",
      "34/34 - 0s - loss: 3709.3867 - mae: 3709.3867\n",
      "Epoch 181/300\n",
      "34/34 - 0s - loss: 3695.9609 - mae: 3695.9609\n",
      "Epoch 182/300\n",
      "34/34 - 0s - loss: 3693.4854 - mae: 3693.4854\n",
      "Epoch 183/300\n",
      "34/34 - 0s - loss: 3691.5898 - mae: 3691.5898\n",
      "Epoch 184/300\n",
      "34/34 - 0s - loss: 3697.9919 - mae: 3697.9919\n",
      "Epoch 185/300\n",
      "34/34 - 0s - loss: 3692.3054 - mae: 3692.3054\n",
      "Epoch 186/300\n",
      "34/34 - 0s - loss: 3695.7466 - mae: 3695.7466\n",
      "Epoch 187/300\n",
      "34/34 - 0s - loss: 3688.8049 - mae: 3688.8049\n",
      "Epoch 188/300\n",
      "34/34 - 0s - loss: 3693.3770 - mae: 3693.3770\n",
      "Epoch 189/300\n",
      "34/34 - 0s - loss: 3684.3000 - mae: 3684.3000\n",
      "Epoch 190/300\n",
      "34/34 - 0s - loss: 3682.4172 - mae: 3682.4172\n",
      "Epoch 191/300\n",
      "34/34 - 0s - loss: 3701.8770 - mae: 3701.8770\n",
      "Epoch 192/300\n",
      "34/34 - 0s - loss: 3685.1741 - mae: 3685.1741\n",
      "Epoch 193/300\n",
      "34/34 - 0s - loss: 3674.1248 - mae: 3674.1248\n",
      "Epoch 194/300\n",
      "34/34 - 0s - loss: 3674.9351 - mae: 3674.9351\n",
      "Epoch 195/300\n",
      "34/34 - 0s - loss: 3672.9150 - mae: 3672.9150\n",
      "Epoch 196/300\n",
      "34/34 - 0s - loss: 3681.3547 - mae: 3681.3547\n",
      "Epoch 197/300\n",
      "34/34 - 0s - loss: 3666.5688 - mae: 3666.5688\n",
      "Epoch 198/300\n",
      "34/34 - 0s - loss: 3672.4158 - mae: 3672.4158\n",
      "Epoch 199/300\n",
      "34/34 - 0s - loss: 3680.3140 - mae: 3680.3140\n",
      "Epoch 200/300\n",
      "34/34 - 0s - loss: 3668.1565 - mae: 3668.1565\n",
      "Epoch 201/300\n",
      "34/34 - 0s - loss: 3666.3298 - mae: 3666.3298\n",
      "Epoch 202/300\n",
      "34/34 - 0s - loss: 3666.9373 - mae: 3666.9373\n",
      "Epoch 203/300\n",
      "34/34 - 0s - loss: 3664.3232 - mae: 3664.3232\n",
      "Epoch 204/300\n",
      "34/34 - 0s - loss: 3655.3015 - mae: 3655.3015\n",
      "Epoch 205/300\n",
      "34/34 - 0s - loss: 3663.1960 - mae: 3663.1960\n",
      "Epoch 206/300\n",
      "34/34 - 0s - loss: 3657.7788 - mae: 3657.7788\n",
      "Epoch 207/300\n",
      "34/34 - 0s - loss: 3657.6460 - mae: 3657.6460\n",
      "Epoch 208/300\n",
      "34/34 - 0s - loss: 3653.1614 - mae: 3653.1614\n",
      "Epoch 209/300\n",
      "34/34 - 0s - loss: 3652.9922 - mae: 3652.9922\n",
      "Epoch 210/300\n",
      "34/34 - 0s - loss: 3658.3428 - mae: 3658.3428\n",
      "Epoch 211/300\n",
      "34/34 - 0s - loss: 3651.9136 - mae: 3651.9136\n",
      "Epoch 212/300\n",
      "34/34 - 0s - loss: 3667.4387 - mae: 3667.4387\n",
      "Epoch 213/300\n",
      "34/34 - 0s - loss: 3656.4417 - mae: 3656.4417\n",
      "Epoch 214/300\n",
      "34/34 - 0s - loss: 3677.7402 - mae: 3677.7402\n",
      "Epoch 215/300\n",
      "34/34 - 0s - loss: 3651.9277 - mae: 3651.9277\n",
      "Epoch 216/300\n",
      "34/34 - 0s - loss: 3644.4092 - mae: 3644.4092\n",
      "Epoch 217/300\n",
      "34/34 - 0s - loss: 3646.0896 - mae: 3646.0896\n",
      "Epoch 218/300\n",
      "34/34 - 0s - loss: 3642.5220 - mae: 3642.5220\n",
      "Epoch 219/300\n",
      "34/34 - 0s - loss: 3648.4802 - mae: 3648.4802\n",
      "Epoch 220/300\n",
      "34/34 - 0s - loss: 3637.4028 - mae: 3637.4028\n",
      "Epoch 221/300\n",
      "34/34 - 0s - loss: 3638.4219 - mae: 3638.4219\n",
      "Epoch 222/300\n",
      "34/34 - 0s - loss: 3646.1243 - mae: 3646.1243\n",
      "Epoch 223/300\n",
      "34/34 - 0s - loss: 3634.4282 - mae: 3634.4282\n",
      "Epoch 224/300\n",
      "34/34 - 0s - loss: 3635.6523 - mae: 3635.6523\n",
      "Epoch 225/300\n",
      "34/34 - 0s - loss: 3632.8640 - mae: 3632.8640\n",
      "Epoch 226/300\n",
      "34/34 - 0s - loss: 3626.3132 - mae: 3626.3132\n",
      "Epoch 227/300\n",
      "34/34 - 0s - loss: 3621.7319 - mae: 3621.7319\n",
      "Epoch 228/300\n",
      "34/34 - 0s - loss: 3629.4216 - mae: 3629.4216\n",
      "Epoch 229/300\n",
      "34/34 - 0s - loss: 3635.1113 - mae: 3635.1113\n",
      "Epoch 230/300\n",
      "34/34 - 0s - loss: 3617.1775 - mae: 3617.1775\n",
      "Epoch 231/300\n",
      "34/34 - 0s - loss: 3615.0081 - mae: 3615.0081\n",
      "Epoch 232/300\n",
      "34/34 - 0s - loss: 3612.9299 - mae: 3612.9299\n",
      "Epoch 233/300\n",
      "34/34 - 0s - loss: 3610.7581 - mae: 3610.7581\n",
      "Epoch 234/300\n",
      "34/34 - 0s - loss: 3619.5613 - mae: 3619.5613\n",
      "Epoch 235/300\n",
      "34/34 - 0s - loss: 3624.1360 - mae: 3624.1360\n",
      "Epoch 236/300\n",
      "34/34 - 0s - loss: 3613.1230 - mae: 3613.1230\n",
      "Epoch 237/300\n",
      "34/34 - 0s - loss: 3617.4771 - mae: 3617.4771\n",
      "Epoch 238/300\n",
      "34/34 - 0s - loss: 3597.5608 - mae: 3597.5608\n",
      "Epoch 239/300\n",
      "34/34 - 0s - loss: 3608.1814 - mae: 3608.1814\n",
      "Epoch 240/300\n",
      "34/34 - 0s - loss: 3604.1812 - mae: 3604.1812\n",
      "Epoch 241/300\n",
      "34/34 - 0s - loss: 3598.7771 - mae: 3598.7771\n",
      "Epoch 242/300\n",
      "34/34 - 0s - loss: 3596.0933 - mae: 3596.0933\n",
      "Epoch 243/300\n",
      "34/34 - 0s - loss: 3592.0952 - mae: 3592.0952\n",
      "Epoch 244/300\n",
      "34/34 - 0s - loss: 3606.4673 - mae: 3606.4673\n",
      "Epoch 245/300\n",
      "34/34 - 0s - loss: 3591.5388 - mae: 3591.5388\n",
      "Epoch 246/300\n",
      "34/34 - 0s - loss: 3586.4480 - mae: 3586.4480\n",
      "Epoch 247/300\n",
      "34/34 - 0s - loss: 3583.7649 - mae: 3583.7649\n",
      "Epoch 248/300\n",
      "34/34 - 0s - loss: 3599.2009 - mae: 3599.2009\n",
      "Epoch 249/300\n",
      "34/34 - 0s - loss: 3583.4290 - mae: 3583.4290\n",
      "Epoch 250/300\n",
      "34/34 - 0s - loss: 3578.5371 - mae: 3578.5371\n",
      "Epoch 251/300\n",
      "34/34 - 0s - loss: 3576.9990 - mae: 3576.9990\n",
      "Epoch 252/300\n",
      "34/34 - 0s - loss: 3580.4487 - mae: 3580.4487\n",
      "Epoch 253/300\n",
      "34/34 - 0s - loss: 3574.2246 - mae: 3574.2246\n",
      "Epoch 254/300\n",
      "34/34 - 0s - loss: 3571.6389 - mae: 3571.6389\n",
      "Epoch 255/300\n",
      "34/34 - 0s - loss: 3566.3042 - mae: 3566.3042\n",
      "Epoch 256/300\n",
      "34/34 - 0s - loss: 3571.6458 - mae: 3571.6458\n",
      "Epoch 257/300\n",
      "34/34 - 0s - loss: 3566.8269 - mae: 3566.8269\n",
      "Epoch 258/300\n",
      "34/34 - 0s - loss: 3585.8738 - mae: 3585.8738\n",
      "Epoch 259/300\n",
      "34/34 - 0s - loss: 3561.8652 - mae: 3561.8652\n",
      "Epoch 260/300\n",
      "34/34 - 0s - loss: 3565.4590 - mae: 3565.4590\n",
      "Epoch 261/300\n",
      "34/34 - 0s - loss: 3564.7356 - mae: 3564.7356\n",
      "Epoch 262/300\n",
      "34/34 - 0s - loss: 3559.4531 - mae: 3559.4531\n",
      "Epoch 263/300\n",
      "34/34 - 0s - loss: 3559.9429 - mae: 3559.9429\n",
      "Epoch 264/300\n",
      "34/34 - 0s - loss: 3559.8318 - mae: 3559.8318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/300\n",
      "34/34 - 0s - loss: 3558.4526 - mae: 3558.4526\n",
      "Epoch 266/300\n",
      "34/34 - 0s - loss: 3559.4216 - mae: 3559.4216\n",
      "Epoch 267/300\n",
      "34/34 - 0s - loss: 3559.4324 - mae: 3559.4324\n",
      "Epoch 268/300\n",
      "34/34 - 0s - loss: 3550.5686 - mae: 3550.5686\n",
      "Epoch 269/300\n",
      "34/34 - 0s - loss: 3557.0735 - mae: 3557.0735\n",
      "Epoch 270/300\n",
      "34/34 - 0s - loss: 3545.2886 - mae: 3545.2886\n",
      "Epoch 271/300\n",
      "34/34 - 0s - loss: 3546.8140 - mae: 3546.8140\n",
      "Epoch 272/300\n",
      "34/34 - 0s - loss: 3543.7268 - mae: 3543.7268\n",
      "Epoch 273/300\n",
      "34/34 - 0s - loss: 3543.1992 - mae: 3543.1992\n",
      "Epoch 274/300\n",
      "34/34 - 0s - loss: 3541.0999 - mae: 3541.0999\n",
      "Epoch 275/300\n",
      "34/34 - 0s - loss: 3537.6238 - mae: 3537.6238\n",
      "Epoch 276/300\n",
      "34/34 - 0s - loss: 3541.2419 - mae: 3541.2419\n",
      "Epoch 277/300\n",
      "34/34 - 0s - loss: 3538.3347 - mae: 3538.3347\n",
      "Epoch 278/300\n",
      "34/34 - 0s - loss: 3538.9609 - mae: 3538.9609\n",
      "Epoch 279/300\n",
      "34/34 - 0s - loss: 3542.1421 - mae: 3542.1421\n",
      "Epoch 280/300\n",
      "34/34 - 0s - loss: 3532.5127 - mae: 3532.5127\n",
      "Epoch 281/300\n",
      "34/34 - 0s - loss: 3534.0762 - mae: 3534.0762\n",
      "Epoch 282/300\n",
      "34/34 - 0s - loss: 3530.0222 - mae: 3530.0222\n",
      "Epoch 283/300\n",
      "34/34 - 0s - loss: 3535.8042 - mae: 3535.8042\n",
      "Epoch 284/300\n",
      "34/34 - 0s - loss: 3529.2568 - mae: 3529.2568\n",
      "Epoch 285/300\n",
      "34/34 - 0s - loss: 3534.1799 - mae: 3534.1799\n",
      "Epoch 286/300\n",
      "34/34 - 0s - loss: 3521.1394 - mae: 3521.1394\n",
      "Epoch 287/300\n",
      "34/34 - 0s - loss: 3521.5371 - mae: 3521.5371\n",
      "Epoch 288/300\n",
      "34/34 - 0s - loss: 3521.7949 - mae: 3521.7949\n",
      "Epoch 289/300\n",
      "34/34 - 0s - loss: 3522.0251 - mae: 3522.0251\n",
      "Epoch 290/300\n",
      "34/34 - 0s - loss: 3525.3982 - mae: 3525.3982\n",
      "Epoch 291/300\n",
      "34/34 - 0s - loss: 3527.8359 - mae: 3527.8359\n",
      "Epoch 292/300\n",
      "34/34 - 0s - loss: 3526.4304 - mae: 3526.4304\n",
      "Epoch 293/300\n",
      "34/34 - 0s - loss: 3517.0630 - mae: 3517.0630\n",
      "Epoch 294/300\n",
      "34/34 - 0s - loss: 3526.2537 - mae: 3526.2537\n",
      "Epoch 295/300\n",
      "34/34 - 0s - loss: 3530.7224 - mae: 3530.7224\n",
      "Epoch 296/300\n",
      "34/34 - 0s - loss: 3514.8032 - mae: 3514.8032\n",
      "Epoch 297/300\n",
      "34/34 - 0s - loss: 3507.2854 - mae: 3507.2854\n",
      "Epoch 298/300\n",
      "34/34 - 0s - loss: 3509.7280 - mae: 3509.7280\n",
      "Epoch 299/300\n",
      "34/34 - 0s - loss: 3520.3450 - mae: 3520.3450\n",
      "Epoch 300/300\n",
      "34/34 - 0s - loss: 3510.6033 - mae: 3510.6033\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_3=tf.keras.Sequential([\n",
    " \n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)   \n",
    "])\n",
    "# compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "#fitting the model:\n",
    "history=model_3.fit(X_train,Y_train,epochs=300,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfb696ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 805us/step - loss: 3215.7161 - mae: 3215.7161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3215.716064453125, 3215.716064453125]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fba99be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot history\n",
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60e1e3",
   "metadata": {},
   "source": [
    "## Question: how long should i train for?\n",
    "* it depends... it's depends on the model you are working on\n",
    "* howeever tensorflow has a solution called earlystopping\n",
    "*early stopping is a compoent we should add to our model , to stop training when there is no improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161b1a9",
   "metadata": {},
   "source": [
    "##  Normalisation and standarization\n",
    "* to get data ready there some  steps that we should folow\n",
    "    1. turn all data into number\n",
    "    2. make sure all of your tensors are the right shape\n",
    "    3. scale features(normalize, or stamdarize, neural network tend to prefer normalization) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248a596",
   "metadata": {},
   "source": [
    "* what is normalization? is a technique often applied as a part of data preparation the goal of normalization is to change the values of numeric columns in the dataset to a commom scale without storing diffrent in in the ranges of values.\n",
    "* age and bmi have diffrent scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91ed3c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X[\"age\"].plot(kind='hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68a85596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['bmi'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b59a07",
   "metadata": {},
   "source": [
    "#### In terms of Scaling values , neural networks tends to prefer normalization\n",
    "* in case when we are not sure we can try both and see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bd9708b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in the insurance dataset\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "656c5c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the data\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2e1aab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Create column transformer (this will help us normalize/preprocess our data)\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create X & y\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "# Build our train and test sets (use random state to ensure same split as before)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "92fac981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-normalized and non-one-hot encoded data example\n",
    "X_train.loc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2d167564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized and one-hot encoded example\n",
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1a505ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noe we are making data preprocessing ,  the only think that we should do is training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6f2487fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 849us/step - loss: 13342.6494 - mae: 13342.6494\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 710us/step - loss: 13333.4785 - mae: 13333.4785\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 683us/step - loss: 13312.0234 - mae: 13312.0234\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 709us/step - loss: 13267.7930 - mae: 13267.7930\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 683us/step - loss: 13189.5830 - mae: 13189.5830\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 739us/step - loss: 13066.4502 - mae: 13066.4502\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 761us/step - loss: 12888.1953 - mae: 12888.1953\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 740us/step - loss: 12644.6523 - mae: 12644.6523\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 750us/step - loss: 12325.5469 - mae: 12325.5469\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 758us/step - loss: 11925.9658 - mae: 11925.9658\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 708us/step - loss: 11454.3350 - mae: 11454.3350\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 738us/step - loss: 10949.8076 - mae: 10949.8076\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 751us/step - loss: 10448.9404 - mae: 10448.9404\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 714us/step - loss: 9951.6250 - mae: 9951.6250\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 778us/step - loss: 9482.7412 - mae: 9482.7412\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 736us/step - loss: 9066.7461 - mae: 9066.7461\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 738us/step - loss: 8721.9854 - mae: 8721.9854\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 743us/step - loss: 8441.2002 - mae: 8441.2002\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 817us/step - loss: 8227.5117 - mae: 8227.5117\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 728us/step - loss: 8081.9766 - mae: 8081.9766\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 761us/step - loss: 7973.8945 - mae: 7973.8945\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7899.1597 - mae: 7899.1597\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7840.3906 - mae: 7840.3906\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 819us/step - loss: 7787.9619 - mae: 7787.9619\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 858us/step - loss: 7749.2622 - mae: 7749.2622\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 712us/step - loss: 7697.9604 - mae: 7697.9604\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 681us/step - loss: 7656.0269 - mae: 7656.0269\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 826us/step - loss: 7613.4780 - mae: 7613.4780\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 771us/step - loss: 7570.9482 - mae: 7570.9482\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 625us/step - loss: 7527.4175 - mae: 7527.4175\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 739us/step - loss: 7483.5947 - mae: 7483.5947\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 647us/step - loss: 7439.4424 - mae: 7439.4424\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 832us/step - loss: 7395.0547 - mae: 7395.0547\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 770us/step - loss: 7346.8120 - mae: 7346.8120\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 710us/step - loss: 7300.0488 - mae: 7300.0488\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 878us/step - loss: 7249.8452 - mae: 7249.8452\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 800us/step - loss: 7199.5303 - mae: 7199.5303\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 823us/step - loss: 7148.4805 - mae: 7148.4805\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 813us/step - loss: 7093.6650 - mae: 7093.6650\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 694us/step - loss: 7038.1797 - mae: 7038.1797\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 802us/step - loss: 6981.7393 - mae: 6981.7393\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 779us/step - loss: 6922.7842 - mae: 6922.7847\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 682us/step - loss: 6860.1724 - mae: 6860.1724\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 723us/step - loss: 6793.7969 - mae: 6793.7969\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 815us/step - loss: 6726.6201 - mae: 6726.6201\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 684us/step - loss: 6657.4683 - mae: 6657.4683\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 761us/step - loss: 6586.3086 - mae: 6586.3086\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 815us/step - loss: 6507.5063 - mae: 6507.5063\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 696us/step - loss: 6428.6021 - mae: 6428.6021\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 735us/step - loss: 6342.7100 - mae: 6342.7100\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 828us/step - loss: 6258.0718 - mae: 6258.0718\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 801us/step - loss: 6164.7046 - mae: 6164.7046\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 677us/step - loss: 6068.6748 - mae: 6068.6748\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 839us/step - loss: 5970.0981 - mae: 5970.0981\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 750us/step - loss: 5862.5625 - mae: 5862.5625\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 708us/step - loss: 5753.9526 - mae: 5753.9526\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 830us/step - loss: 5638.0942 - mae: 5638.0942\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 749us/step - loss: 5519.8682 - mae: 5519.8682\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 750us/step - loss: 5401.3198 - mae: 5401.3198\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 675us/step - loss: 5277.3506 - mae: 5277.3506\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 797us/step - loss: 5149.7637 - mae: 5149.7637\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 725us/step - loss: 5019.3535 - mae: 5019.3535\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 724us/step - loss: 4889.6865 - mae: 4889.6865\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 689us/step - loss: 4756.8560 - mae: 4756.8560\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 628us/step - loss: 4629.4365 - mae: 4629.4365\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 625us/step - loss: 4503.5991 - mae: 4503.5991\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 652us/step - loss: 4392.9922 - mae: 4392.9922\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 728us/step - loss: 4284.3862 - mae: 4284.3862\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 628us/step - loss: 4182.6182 - mae: 4182.6182\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 647us/step - loss: 4089.5720 - mae: 4089.5720\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 670us/step - loss: 4003.3896 - mae: 4003.3896\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 689us/step - loss: 3929.0093 - mae: 3929.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 652us/step - loss: 3866.3110 - mae: 3866.3110\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 701us/step - loss: 3813.7144 - mae: 3813.7144\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 652us/step - loss: 3773.0315 - mae: 3773.0315\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 788us/step - loss: 3744.1995 - mae: 3744.1995\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 729us/step - loss: 3719.6870 - mae: 3719.6870\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 709us/step - loss: 3702.9109 - mae: 3702.9109\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 684us/step - loss: 3691.8792 - mae: 3691.8792\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 674us/step - loss: 3682.8350 - mae: 3682.8350\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 689us/step - loss: 3676.9768 - mae: 3676.9768\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 779us/step - loss: 3673.9492 - mae: 3673.9492\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 626us/step - loss: 3667.8452 - mae: 3667.8452\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 685us/step - loss: 3664.5757 - mae: 3664.5757\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 622us/step - loss: 3661.8562 - mae: 3661.8562\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 715us/step - loss: 3660.3049 - mae: 3660.3049\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 617us/step - loss: 3657.5134 - mae: 3657.5134\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 646us/step - loss: 3655.2202 - mae: 3655.2202\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 613us/step - loss: 3653.8831 - mae: 3653.8831\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 693us/step - loss: 3652.0198 - mae: 3652.0198\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 656us/step - loss: 3648.9990 - mae: 3648.9990\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 813us/step - loss: 3648.4463 - mae: 3648.4463\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 671us/step - loss: 3646.2300 - mae: 3646.2300\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 641us/step - loss: 3644.4377 - mae: 3644.4377\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 629us/step - loss: 3645.8772 - mae: 3645.8772\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 767us/step - loss: 3642.2573 - mae: 3642.2573\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 662us/step - loss: 3640.1189 - mae: 3640.1189\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 617us/step - loss: 3638.0647 - mae: 3638.0647\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 694us/step - loss: 3637.2051 - mae: 3637.2051\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 624us/step - loss: 3636.1707 - mae: 3636.1707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x202099a5ca0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "#create the model\n",
    "model_processing=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100) ,\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "])\n",
    "\n",
    "model_processing.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "#fiting the model\n",
    "\n",
    "model_processing.fit(X_train_normal,Y_train,epochs=100,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "eb00a822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 951us/step - loss: 3438.7844 - mae: 3438.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3438.784423828125, 3438.784423828125]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_processing.evaluate(X_test_normal,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization deos not garantie the model performance but it's something worth to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e2ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e522a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6dc8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
